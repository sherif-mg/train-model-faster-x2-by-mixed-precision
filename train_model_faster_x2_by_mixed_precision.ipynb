{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3THzC89sT57",
        "outputId": "f04f1eb3-a050-4398-d837-1a269eb202ad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (6.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2022.6.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "  \n",
        "od.download(\"https://www.kaggle.com/datasets/kiraio/organizeflowersdataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGsNKxNhsdoz",
        "outputId": "0b5e5f7a-5522-4d69-b1b3-e631a41c7ecb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: sherifmagdyabdellah\n",
            "Your Kaggle Key: ··········\n",
            "Downloading organizeflowersdataset.zip to ./organizeflowersdataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 514M/514M [00:06<00:00, 81.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, GlobalAveragePooling2D,Activation\n",
        "from keras.layers import Dense ,Conv2D,Flatten,Dropout,ReLU,Activation,Input\n",
        "import os\n",
        "import cv2\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import TensorBoard\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "random.seed(10)\n",
        "np.random.seed(10)\n",
        "tf.random.set_seed(10)"
      ],
      "metadata": {
        "id": "aE6_BE2BpSBf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# variable\n",
        "## image path\n",
        "train_data_dir = '/content/organizeflowersdataset/change_flowers/change_flowers/train'\n",
        "validation_data_dir = '/content/organizeflowersdataset/change_flowers/change_flowers/validation'\n",
        "## other\n",
        "img_width, img_height = 200, 200\n",
        "nb_train_samples = 100\n",
        "nb_validation_samples = 800\n",
        "top_epochs = 50\n",
        "fit_epochs = 50\n",
        "batch_size = 24\n",
        "nb_classes = 5\n",
        "nb_epoch = 10"
      ],
      "metadata": {
        "id": "gutGkibYqfyW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=[]\n",
        "y_train=[]\n",
        "for subdir, dirs, files in os.walk(train_data_dir):\n",
        "    for file in files:\n",
        "        img = cv2.imread(os.path.join(subdir, file))\n",
        "        x_train.append(cv2.resize(img,(200,200))/255.0) \n",
        "        y_train.append(subdir.split('/')[-1])"
      ],
      "metadata": {
        "id": "geiy6mcU2DK3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid=[]\n",
        "y_valid=[]\n",
        "for subdir, dirs, files in os.walk(validation_data_dir):\n",
        "    for file in files:\n",
        "        img = cv2.imread(os.path.join(subdir, file))\n",
        "        x_valid.append(cv2.resize(img,(200,200))/255.0) \n",
        "        y_valid.append(subdir.split('/')[-1])"
      ],
      "metadata": {
        "id": "tk2_pVc43M26"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y_train)\n",
        "y_train=le.transform(y_train)\n",
        "y_valid=le.transform(y_valid)"
      ],
      "metadata": {
        "id": "t2-QrIEj4Mot"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "x_valid, y_valid = shuffle(x_valid, y_valid)\n",
        "x_train, y_train = shuffle(x_train, y_train)"
      ],
      "metadata": {
        "id": "fpIYXA007WdL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=np.array(x_train[0:1500])\n",
        "y_train=y_train[0:1500]\n",
        "x_valid=np.array(x_valid[0:500])\n",
        "y_valid=y_valid[0:500]"
      ],
      "metadata": {
        "id": "mZ994LAB7oO9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  # import vgg16 model\n",
        "  input_tensor = Input(shape=(img_width, img_height, 3))\n",
        "  vgg16 = keras.applications.vgg16.VGG16(weights=\"imagenet\", include_top=False, input_tensor=input_tensor)\n",
        "\n",
        "  # creating an FC layer\n",
        "  top_model = Sequential()\n",
        "  top_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
        "  top_model.add(Dense(256, activation='relu'))\n",
        "  top_model.add(Dropout(0.5))\n",
        "  top_model.add(Dense(nb_classes, name='dense_output'))\n",
        "  top_model.add(Activation('softmax', dtype='float32', name='predictions'))\n",
        "\n",
        "  # bound VGG 16 and FC layer\n",
        "  vgg_model = Model(inputs=vgg16.input, outputs=top_model(vgg16.output))\n",
        "\n",
        "  # create model\n",
        "  vgg_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                optimizer=\"adam\",\n",
        "                metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  return vgg_model\n"
      ],
      "metadata": {
        "id": "uJRri4tJqomg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_without_mixedPrecision=create_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-ICdZ4prTBc",
        "outputId": "46d83476-3e15-4fae-ee9e-b70ae66cad7d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_without_mixedPrecision.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhZv9yW7rUxB",
        "outputId": "9aea2718-f7d7-44f8-8085-5da5d713f102"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 200, 200, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 200, 200, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 200, 200, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 100, 100, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 100, 100, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 100, 100, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 50, 50, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 50, 50, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 50, 50, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 50, 50, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 25, 25, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 25, 25, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 12, 12, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 5)                 4720133   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,434,821\n",
            "Trainable params: 19,434,821\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "training_start = time.time()\n",
        "history_without_mixedPrecision = model_without_mixedPrecision.fit(\n",
        "          x_train,y_train,batch_size=128,\n",
        "          epochs=20,\n",
        "          validation_data=(x_valid,y_valid),\n",
        "          shuffle=True,\n",
        "          verbose=1)\n",
        "training_stop = time.time()\n",
        "training_time = training_stop - training_start\n",
        "print(f\"Training time: {training_time}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eudzNxKutnu_",
        "outputId": "f8467348-3f4d-411f-ded6-e1e974e54f43"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "12/12 [==============================] - 72s 4s/step - loss: 2.5768 - accuracy: 0.2333 - val_loss: 1.7135 - val_accuracy: 0.1200\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 2.0114 - accuracy: 0.2320 - val_loss: 1.6035 - val_accuracy: 0.1680\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.5712 - accuracy: 0.3187 - val_loss: 1.4133 - val_accuracy: 0.4480\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.4286 - accuracy: 0.4040 - val_loss: 1.3664 - val_accuracy: 0.4060\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.3061 - accuracy: 0.4567 - val_loss: 1.2444 - val_accuracy: 0.4540\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.1977 - accuracy: 0.4993 - val_loss: 1.1934 - val_accuracy: 0.5120\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.1611 - accuracy: 0.5153 - val_loss: 1.2216 - val_accuracy: 0.5020\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.0795 - accuracy: 0.5720 - val_loss: 1.1336 - val_accuracy: 0.5380\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.0574 - accuracy: 0.5820 - val_loss: 1.1651 - val_accuracy: 0.5380\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.0212 - accuracy: 0.6020 - val_loss: 1.2910 - val_accuracy: 0.4880\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.0071 - accuracy: 0.5993 - val_loss: 1.1231 - val_accuracy: 0.5360\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.9509 - accuracy: 0.6487 - val_loss: 1.0758 - val_accuracy: 0.5700\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.9006 - accuracy: 0.6747 - val_loss: 1.0996 - val_accuracy: 0.5840\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.8560 - accuracy: 0.6833 - val_loss: 1.1383 - val_accuracy: 0.5240\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.8412 - accuracy: 0.6840 - val_loss: 1.1185 - val_accuracy: 0.5940\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.8319 - accuracy: 0.6920 - val_loss: 1.1136 - val_accuracy: 0.5940\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.7853 - accuracy: 0.7060 - val_loss: 1.2252 - val_accuracy: 0.5220\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.8368 - accuracy: 0.6833 - val_loss: 1.1944 - val_accuracy: 0.5580\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.8228 - accuracy: 0.7047 - val_loss: 1.0934 - val_accuracy: 0.6000\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 19s 2s/step - loss: 0.6748 - accuracy: 0.7440 - val_loss: 1.0665 - val_accuracy: 0.5860\n",
            "Training time: 429.5039041042328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "OOWJG5ot-0Lk",
        "outputId": "b5533f25-14d9-4396-8aef-a2a96b7cfae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1434"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)"
      ],
      "metadata": {
        "id": "fgaYf8GWucj6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_mixedPrecision = create_model()"
      ],
      "metadata": {
        "id": "2431pBXIueaG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "training_start_1 = time.time()\n",
        "history_model_mixedPrecision = model_mixedPrecision.fit(\n",
        "          x_train,y_train,batch_size=128,\n",
        "          epochs=20,\n",
        "          validation_data=(x_valid,y_valid),\n",
        "          shuffle=True,\n",
        "          verbose=1)\n",
        "training_stop_1 = time.time()\n",
        "training_time_1 = training_stop_1 - training_start_1\n",
        "print(f\"Training time: {training_time_1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atEncq0sukPM",
        "outputId": "1192fc7b-6a14-4c81-ef0c-7a50819f94f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "12/12 [==============================] - 165s 7s/step - loss: 6.3886 - accuracy: 0.2220 - val_loss: 1.6071 - val_accuracy: 0.1200\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 10s 862ms/step - loss: 1.6333 - accuracy: 0.2587 - val_loss: 1.6008 - val_accuracy: 0.2280\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 10s 856ms/step - loss: 1.5731 - accuracy: 0.3227 - val_loss: 1.4765 - val_accuracy: 0.4300\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 10s 855ms/step - loss: 1.5561 - accuracy: 0.3267 - val_loss: 1.5027 - val_accuracy: 0.4400\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 10s 854ms/step - loss: 1.5335 - accuracy: 0.3387 - val_loss: 1.5164 - val_accuracy: 0.3700\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 10s 856ms/step - loss: 1.3585 - accuracy: 0.4280 - val_loss: 1.4188 - val_accuracy: 0.3180\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 10s 852ms/step - loss: 1.2741 - accuracy: 0.4553 - val_loss: 1.3084 - val_accuracy: 0.4880\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 10s 851ms/step - loss: 1.2067 - accuracy: 0.5140 - val_loss: 1.2294 - val_accuracy: 0.4860\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 10s 849ms/step - loss: 1.1652 - accuracy: 0.5353 - val_loss: 1.1957 - val_accuracy: 0.5320\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 10s 848ms/step - loss: 1.0983 - accuracy: 0.5580 - val_loss: 1.3065 - val_accuracy: 0.4780\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 10s 846ms/step - loss: 1.1021 - accuracy: 0.5573 - val_loss: 1.1538 - val_accuracy: 0.5360\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 10s 847ms/step - loss: 1.0781 - accuracy: 0.5813 - val_loss: 1.1809 - val_accuracy: 0.5300\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 10s 849ms/step - loss: 1.0612 - accuracy: 0.5860 - val_loss: 1.1428 - val_accuracy: 0.5400\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 10s 849ms/step - loss: 0.9851 - accuracy: 0.6207 - val_loss: 1.1527 - val_accuracy: 0.5360\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 10s 848ms/step - loss: 0.9233 - accuracy: 0.6360 - val_loss: 1.1442 - val_accuracy: 0.5740\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 10s 846ms/step - loss: 0.9511 - accuracy: 0.6367 - val_loss: 1.1560 - val_accuracy: 0.5620\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 10s 849ms/step - loss: 0.9343 - accuracy: 0.6427 - val_loss: 1.0868 - val_accuracy: 0.5540\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 10s 848ms/step - loss: 0.9117 - accuracy: 0.6620 - val_loss: 1.2785 - val_accuracy: 0.4920\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 10s 848ms/step - loss: 0.9031 - accuracy: 0.6520 - val_loss: 1.2565 - val_accuracy: 0.5180\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 10s 846ms/step - loss: 0.8719 - accuracy: 0.6567 - val_loss: 1.0625 - val_accuracy: 0.5960\n",
            "Training time: 357.7890045642853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "after we train two models one by float32 precision and one with mixed precision we conclude that model with mixed precision faster than default double in each epoch (default model time per epoch =20 s\n",
        "mixed precision 10 s per epoch )\n",
        "and That will be much clearer in deeper model with huge train data"
      ],
      "metadata": {
        "id": "DjsKkuaFw5Oe"
      }
    }
  ]
}